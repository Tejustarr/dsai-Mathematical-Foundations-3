{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Problems â€” Session 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: Implement gradient_descent(f, grad, x0, alpha, iters)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def gradient_descent(f,grad,x0,alpha,iters):\n    x=x0.copy(); hist=[x]\n    for _ in range(iters):\n        x=x-alpha*grad(x)\n        hist.append(x.copy())\n    return hist\n\nimport numpy as np\nf=lambda v: (v[0]-1)**2+(v[1]+2)**2\ng=lambda v: np.array([2*(v[0]-1),2*(v[1]+2)])\ntraj=gradient_descent(f,g,np.array([0.,0.]),0.1,50)\ntraj[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: Implement stochastic_gradient_descent for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n\ndef sgd(X,y,iters=10,alpha=0.1):\n    w=np.zeros(X.shape[1])\n    for epoch in range(iters):\n        for i in range(len(y)):\n            xi=X[i]; yi=y[i]\n            p=1/(1+np.exp(-xi@w))\n            grad=xi*(p-yi)\n            w-=alpha*grad\n    return w\n\nX=np.array([[1,1,1],[1,2,1],[1,3,1]])\ny=np.array([0,0,1])\nprint(sgd(X,y,10,0.1))"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}